{
    "collab_server" : "",
    "contents" : "---\ntitle: 'Tutorial for R package TreatmentSelection '\noutput:\n  html_document:\n    theme: united\n---\n\n#  {.tabset .tabset-fade .tabset-pills}\n\n## Overview of the package\n\nThis package implements basic methodology for evaluating one or more biomarkers for their ability to guide patient treatment recommendations.\n\nThe methodology assumes that the data come from a randomized and controlled trial (RCT) comparing two treatment options, which we refer to as \"treatment\" and \"no treatment\". These could be, for example, two different active prophylactic or therapeutic interventions, or an experimental intervention and a standard of care.  Subjects are followed for the development of a binary clinical outcome or event within a specified time-frame following treatment/no treatment.  The biomarker(s) are assumed to be measured at baseline; they could be anything from patient demographics or clinical characteristics, to traditional biomarker measurments or the results of imaging or genetic or proteomic analyses.  The methodology accommodates settings where the biomarker(s) are measured on all RCT participants, and also settings in which participants are retrospectively sub-sampled based on clinical outcome and/or treatment assignment for marker measurement. \n\n\n## Install the package \n\nThis tutorial uses the Treatment Selection package (v 2.0.0) to analyze the example data provided in the package.\n\n\nThe current version of the package is on github. Use the `devtools` package to install the package:\n\n```{r, eval=FALSE}\nif (!require(\"devtools\")) install.packages(\"devtools\")\ndevtools::install_github(\"mdbrown/TreatmentSelection\")\n```\n\nFirst, load the example data set for this package called `tsdata`. Four markers are included in the data example, a ''weak'' and a ''strong'' marker ($Y1$ and $Y2$ respectively), along with a weak/strong discrete markers. \n\n## First steps \n\nLoad the example data set for this package called `tsdata`. These are hypothetical data from an RCT with a binary outcome (`outcome`) and treatment assignment (`trt`). Four markers, measured on all RCT participants, are included-- a ''weak'' and a ''strong'' marker (`Y1` and `Y2` respectively), along with binary versions of these markers. \n\n```{r, warning = FALSE}\nlibrary(TreatmentSelection)\nset.seed(12321)\n\ndata(tsdata)\n\ntsdata[1:5, ]\n```\n\n### Evaluate performance of user-specified marker-based treatment rule\n\nFor a pre-defined marker-based treatment rule, we provide a simple function to estimate point estimates of performance measures. This is done using the `trtsel_measures()` function.  The user must specify a vector of clinical outcomes, a vector of treatment assigments, and a vector of marker-based treatment recommendations based on the pre-specified rule.\n\nHere we let `Y1_disc` represent a user-specified treatment rule and evaluate its performance.  \n\n```{r}\n\ntrtsel_measures(event = tsdata$event, trt = tsdata$trt, trt.rule = tsdata$Y1_disc, default.trt = \"trt all\" )\n\n\ntrtsel_measures(event = surv_tsdata$di, \n                time = surv_tsdata$xi,\n                trt = surv_tsdata$trt, \n                trt.rule = as.numeric(surv_tsdata$Y > 0), \n                prediction.time = 1, \n                default.trt = \"trt none\" )\n\n```\n\n\nWe can also fit our own risk model using GLM, use this model to develop a marker-based treatment recommendation, and evaluate its performance. This allows us to obtain model-based estimates of performance:\n\n\n```{r}\n\nmod <- glm(event~trt*Y1_disc,  data = tsdata, family = binomial())\n\ntsdata.0 <- tsdata; \ntsdata.0$trt = 0 \ntsdata.1 <- tsdata;\ntsdata.1$trt = 1\ndelta.hat <- predict(mod, newdata= tsdata.0, type = \"response\") - predict(mod, newdata= tsdata.1, type = \"response\")\n\ntrtsel_measures(event = tsdata$event, trt = tsdata$trt, trt.rule = 1- tsdata$Y1_disc, trt.effect = delta.hat )\n\n```\n\n## Create TrtSel objects \n\nAn alternative to providing a pre-specified treatment rule the user can use the data to fit a risk model and to develop a treatment rule based on estimated treatment effect. \n\nThe user can do this by first creating a treatment selection R object using the function `trtsel`. Creating this object entails estimating risk of the clinical outcome given treatment and marker, i.e. fitting a \"risk model\".  Here, logistic regression is used (`link=\"logit\"`) and the formula is specified in the first argument.  The default treatment strategy-- that which would be recommended in the absence of marker measurements-- is specified as `default.trt=\"trt all\"`.  The methodology considers marker-specific treatment rules or policies that recommend treatment if the marker-specific treatment effect-- on the risk difference scale-- is above a specified `thresh`; the default is `thresh = 0`.  (Alternatively, see the tab on \"additional features\"\" to see how an arbitrary user-specified treatment rule can be evaluated.)  The `study design=\"RCT\"` indicates that the markers are measured on all RCT participants.   \n\n\n\n```{r}\n\ntrtsel.Y1 <- trtsel(event ~ Y1*trt, \n                    treatment.name = \"trt\", \n                    data = tsdata, \n                    study.design = \"RCT\",\n                    link = \"logit\", \n                    default.trt = \"trt all\")\n\ntrtsel.Y1\n```\n\n\n\nAs we see above, the `trtsel.Y1` object contains information about the study design, the fitted risk model, the fitted risk given each treatment, and the estimated marker-specific treatment effect (on the risk difference scale) for each individual.  This object also contains the treatment recommendation for each subject, based on a treatment rule that recommends treatment if the estimated treatment effect is above `thresh`; here `thresh = 0`. \n\nThis is what a `trtsel` object looks like for a binary marker. \n\n```{r}\n# Y2_disc = as.numeric(Y2>0)\n\ntrtsel.Y2_disc <- trtsel(event ~ trt*(Y2_disc), \n                         treatment.name = \"trt\",\n                         data = tsdata, \n                         study.design = \"RCT\", \n                         link = \"logit\")\n```\n\n\n\nSee `?trtsel` for more information. \n\nNow that we have created trtsel objects, we can assess the calibration of the risk models; and plot, evaluate, and compare markers. \n\n\n\n## Assess model calibration \n\nIt is important to assess the fit of the risk model to the data.  The package implements methods for examining calibration.  \n\nHere we compare (average) predicted and observed risk values by decile ('group = 10') of fitted risk, for each treatment group.  The risks are shown on the log scale.  The Hosmer-Lemeshow goodness of fit test is used to detect evidence of mis-calibration by treatment group.\n\n```{r}\ncalibrate(trtsel.Y1, \n          groups = 10, \n          plot = \"treatment effect\", \n          trt.names = c(\"chemo.\", \"no chemo.\"), \n          point.color = \"lightcoral\", \n          line.color = \"black\")\n\n\ncalibrate(trtsel.Y1, \n          groups = 10, \n          plot = \"risk.t0\", \n          trt.names = c(\"chemo.\", \"no chemo.\"), \n          point.color = \"lightcoral\", \n          line.color = \"black\")\n```\n\n\nSee `?calibrate.trtsel` for more plot options. \n\n\n## Plot  \n\n\nThe `plot()` function allows us to visually assess the ability of the marker or markers to predict the treatment effect.\n\n#### Risk curves\nRisk curves apply to individual markers.  They are plots of estimated risk of the clinical outcome as a function of the marker, for each treatment group.  The two risk curves are aligned with respect to marker percentile, but the option `show.marker.axis=TRUE` adds a second x-axis showing the marker values corresponding to each percentile.  Pointwise confidence intervals, obtained using the bootstrap, can be added (`ci=\"vertical\"`).\n\n```{r}\nplot(trtsel.Y1, \n            main = \"Y1: Oncotype-DX-like marker\", \n            plot.type = \"risk\", \n            ci = \"vertical\", \n            conf.bands = TRUE, \n            bootstraps = 50,       #more bootstraps should be run than this in practice!\n            trt.names = c(\"chemo.\", \"no chemo.\"), \n            show.marker.axis = FALSE)\n```\n\n\nThis is what the plot looks like for a binary marker:\n\n\n```{r}\ntmp <- plot(trtsel.Y2_disc,\n                   main = \"Discrete version of Y2\", \n                   plot.type = \"risk\", \n                   ci = \"vertical\", \n                   conf.bands = TRUE, \n                   bootstraps = 50, \n                   trt.names = c(\"chemo.\", \"no chemo.\"))\n```\n\n\nNote that `tmp` is a list with elements `plot` that holds the ggplot output, and `ci.bounds` which holds the information regarding the confidence bounds. \n\n\n```{r}\ntmp$ci.bounds\n```\n\n#### Treatment effect curves\n\nTreatment effect curves apply both to univariate and multivariate markers.  They show the distribution of marker-specific treatment effects. Using `plot.type = \"treatment effect\"` produces a reverse-CDF-type plot:\n\n\n```{r}\nplot(trtsel.Y1, \n            plot.type = \"treatment effect\", \n            ci = \"horizontal\", \n            conf.bands = TRUE, \n            bootstraps = 50)\n```\n\nAlternatively, using `plot.type = \"cdf\"` produces a traditional CDF of the treatment effects:\n\n```{r}\nplot(trtsel.Y1, \n            plot.type = \"cdf\", \n            ci = \"vertical\", \n            conf.bands = TRUE, \n            bootstraps = 50)\n\n```\n\n\nHere is an example of a treatment effect plot for a discrete marker:\n\n```{r}\nplot(trtsel.Y2_disc, \n    plot.type = \"treatment effect\", \n    conf.bands = TRUE, \n    bootstraps = 50)\n```\n\n \n#### Selection impact plot\n\n\nThe selection impact plot also applies to both univariate and multivariate markers.  They show the population rate of the clinical outcome as a function of the proportion of the population recommended treatment according a marker-specific treatment rule.  Rules that recommend treatment based on the marker-specific treatment effect (on the risk difference scale) are considered, and are indexed by the proportion of the population recommended treatment according to the rule.  The outcome rates under \"treat all\" and \"treat none\" policies are shown for comparison.\n\n```{r}\nplot(trtsel.Y1, \n     plot.type = \"selection impact\", \n     ci = \"vertical\", \n     conf.bands = TRUE, \n     bootstraps = 50)\n```\n\n\n## Evaluate marker performance  \n\nThe function `evaluate()` provides estimates of measures of marker performance.  A wide variety of performance measures are estimated-- some which depend on a specified treatment rule and some which do not.  For the former, the rule is inherited from the `trtsel` object.  Confidence intervals are calculated using the quantile bootstrap; in every bootstrap sample the risk model is re-fit and the model performance measures are re-estimated.\n\n```{r}\ntmp <- evaluate(trtsel.Y1, bias.correct = TRUE, bootstraps = 50)\ntmp\n```\n\nThe `evaluate` function used this way both fit and evaluates a risk model using the same data, which is known to bias performance measure estimates to be overly optimistic. To correct for this bias, the evaluate function by default sets `bias.correct=TRUE`. This implements bootstrap bias correction via the ``refined bootstrap\" method described in Efron and Tibshirani 1994. \n\nIn short, we sample $B$ bootstrap datasets. For each, obtain a new treatment selection rule based on the re-fit model and calculate the difference in estimated performance of this rule using the bootstrap vs. original data.  The average of these differences estimates the bias.  We shift naive performance estimates and confidence intervals down by the estimated bias.\n\nHere is what performance evaluation looks like for a discrete marker:\n\n```{r}\n# discrete marker\nevaluate(trtsel.Y2_disc, bootstraps = 50)\n```\n\n## Compare markers \n\n\nTwo markers-- or marker-specific treatment rules-- can be compared using the `compare()` function.  Note that the `compare()` function requires that that the treatment and outcome labels are identical for the two markers/treatment rules.  \n\nHere, we compare the continuous markers `Y1` and `Y2`.  The first step is to create a `trtsel` object for `Y2`.    \n\n\n```{r}\n# trtsel object for markers 1 and 2\ntrtsel.Y2 <- trtsel(event~trt*(Y2 + Y1), \n                    treatment.name = \"trt\", \n                    data = tsdata, \n                    default.trt = \"trt all\")\n```\n\nA suite of performance measures is estimated for each marker, and marker-comparisons are based on Wald hypothesis tests for differences in measures with variances estimated using the bootstrap.  \n\n```{r}\n# Compare the markers based on summary measures\nmycompare <- compare(trtsel1 = trtsel.Y1, \n                     trtsel2 = trtsel.Y2,\n                     bias.correct =TRUE, \n                     model.names = c(\"Y1\", \"Y1 + Y2\"), \n                     bootstraps = 50,\n                     ci = \"vertical\")\nmycompare\n```\n\n\n```{r}\n## Compare two discrete markers Y1_disc = as.numeric(Y1>mean(Y1))\ntrtsel.Y1_disc <- trtsel(event~Y1_disc*trt, \n                         treatment.name = \"trt\", \n                         data = tsdata)\n\n\ncompare(trtsel1 = trtsel.Y1_disc, \n        trtsel2 = trtsel.Y2_disc, \n        bias.correct = TRUE, \n        ci = \"vertical\", \n        offset = 0.2, \n        bootstraps = 50, \n        conf.bands = TRUE, \n        annotate.plot = TRUE)\n```\n\nSee `?compare.trtsel` for more options.\n\n## Additional features \n\n### Specifying fitted risks \n\nAn alternative to specifing one or more markers and fitting a risk model is for the user to specify fitted risks given treatment and no treatment for each subject.  Importantly, in this case the inference provided based on bootstrap confidence intervals is conditional on these user-specified fitted risks.  \n\nHere, we illustrate this by fitting a risk model for `Y2` using the `glm()` function, and then feed the fitted risks into the `trtsel()` function:\n\n```{r}\n#calculate model fit\nmymod <- glm(event~trt*(Y2), data= tsdata, family = binomial(\"logit\"))\n\ntsdata$fitted.t0 <- predict(mymod, newdata=data.frame(trt = 0,Y1 = tsdata$Y1, Y2 = tsdata$Y2), type = \"response\")\ntsdata$fitted.t1 <- predict(mymod, newdata=data.frame(trt = 1,Y1 = tsdata$Y1, Y2 = tsdata$Y2), type = \"response\")\n\nmyfitted.trtsel <- trtsel( event~trt, treatment.name = \"trt\", \n                         data = tsdata,\n                         fittedrisk.t0 = \"fitted.t0\",\n                         fittedrisk.t1 = \"fitted.t1\",\n                         study.design = \"RCT\", \n                         default.trt = \"trt all\")\n\n```\n\nWe can now use this `trtsel` object to plot and evaluate performance just as before, but confidence intervals are narrower because they are conditional on the fitted risk model. \n\n```{r}\nplot(myfitted.trtsel, bootstraps = 50, plot.type = \"risk\",\n     ci = \"vertical\", show.marker.axis = FALSE)\n```\n\n### Time-to-event outcomes\n\n\n\n\n\n\n## References\n\nEfron B, Tibshirani R. **An Introduction to the Bootstrap.**  New York:  Chapman& Hall, 1994.\n\nSong X, Pepe MS. Evaluating markers for selecting a patient's treatment.\n**Biometrics.** 2004;60(4):874-883.\n\nHuang Y, Sullivan Pepe M, Feng Z. Evaluating the predictiveness of a continuous marker. **Biometrics.** 2007;63:1181-8.\n\nJanes H, Pepe MS, Bossuyt PM, et al. Measuring the performance of markers\nfor guiding treatment decisions. **Ann Intern Med.** 2011;154(4):253-259.\n\nJanes H, Brown MD, Huang Y, et al. An approach to evaluating and comparing\nbiomarkers for patient treatment selection. **Int J Biostat.** 2014;10(1):99-\n121.",
    "created" : 1473728985107.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2121379143",
    "id" : "CE44426",
    "lastKnownWriteTime" : 1474495975,
    "last_content_update" : 1474495975481,
    "path" : "~/TreatmentSelection/inst/example/tutorial.Rmd",
    "project_path" : "inst/example/tutorial.Rmd",
    "properties" : {
        "ignored_words" : "TrtSel,trtsel,ggplot,trt,Janes,Pepe,Biomarkers,TreatmentSelection,toc,github\n",
        "source_window_id" : ""
    },
    "relative_order" : 6,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}